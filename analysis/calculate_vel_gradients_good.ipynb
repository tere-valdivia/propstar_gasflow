{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9638f837-8bb3-4673-8222-3b8183fd120e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Velocity gradients and divergence in gas structure\n",
    "\n",
    "We calculate the velocity gradients $\\nabla$v of the velocity field of each molecule. This will tell us about local motions within the fibers. For this, we use the velocity_tools package (Pineda et al.)\n",
    "\n",
    "We also compare the velocity gradients with the polarization vectors to see if the kinematics are influenced by magnetic fields.\n",
    "\n",
    "For this, first we need the velocity gradient of HC$_3$N and N$_2$H$^+$ $\\nabla$v in km s$^{-1}$ pc$^{-1}$, in their native resolutions and in a common one. we modify the resolution of HC$_3$N for this. From 'clustering/comparison_velocities_N2Hp_HC3N.ipynb' we have the clusters velocities in the same pixel grid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a23ffda-13ad-40d1-8e4e-7550d1dbf866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.wcs import WCS\n",
    "from matplotlib import cm\n",
    "from astropy.coordinates import SkyCoord\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/home/mvaldivi/velocity_tools/')\n",
    "from velocity_tools import vgrad\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a513eb-a80b-4014-b86c-c55dc6c86f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gaussian fit results\n",
    "\n",
    "gaussfitfolder = '../bayes_frame/nested-sampling/'\n",
    "hc3n1gfile = gaussfitfolder + 'HC3N/NGC1333-SE-mle-x1_filtered_QA.fits'\n",
    "hc3n2gfile = gaussfitfolder + 'HC3N/NGC1333-SE-mle-x2_filtered_QA.fits'\n",
    "hc3n3gfile = gaussfitfolder + 'HC3N/NGC1333-SE-mle-x3_filtered_QA.fits'\n",
    "n2hp1gfile = gaussfitfolder + 'N2Hp/NGC1333-SE-mle-x1_filtered_QA.fits'\n",
    "n2hp2gfile = gaussfitfolder + 'N2Hp/NGC1333-SE-mle-x2_filtered_QA.fits'\n",
    "\n",
    "gaussifitfiles = np.array([hc3n1gfile, hc3n2gfile, hc3n3gfile, n2hp1gfile, n2hp2gfile])\n",
    "\n",
    "# per fiber\n",
    "clusterfolder = '../clustering/'\n",
    "hc3nbluefile = clusterfolder + 'clusters_blue_HC3N.fits'\n",
    "hc3nredfile = clusterfolder + 'clusters_red_HC3N.fits'\n",
    "n2hpbluefile = clusterfolder + 'cluster_blue_HDBSCAN_N2Hp.fits'\n",
    "n2hpredfile = clusterfolder + 'cluster_red_HDBSCAN_N2Hp.fits'\n",
    "\n",
    "fiberfiles = np.array([hc3nbluefile, hc3nredfile, n2hpbluefile, n2hpredfile])\n",
    "\n",
    "# per cluster\n",
    "# HC3N has 8 clusters\n",
    "\n",
    "hc3nclusterbase = clusterfolder + 'cluster{}_HDBSCAN_HC3N.fits'\n",
    "hc3nclusterfiles = [hc3nclusterbase.format(i) for i in range(7)]\n",
    "\n",
    "headertodel = ['crval3', 'cdelt3', 'cunit3', 'ctype3', 'crpix3', 'naxis3']\n",
    "\n",
    "overwrite=False\n",
    "\n",
    "# we need to save the velocity in a separate file to use vgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7e6cc5-942c-44c2-bafa-ea0e49660034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def separate_vel_comp(params, parheader):\n",
    "    newhead = parheader.copy()\n",
    "    newhead['naxis'] = 2\n",
    "    newhead['wcsaxes'] = 2\n",
    "    for flag in headertodel:\n",
    "        del newhead[flag]\n",
    "    if parheader[\"NAXIS3\"] == 6:\n",
    "        velfield = params[1]\n",
    "        velerror = params[4]\n",
    "        \n",
    "    elif parheader[\"NAXIS3\"] == 12:\n",
    "        velfield = [params[1], params[4]]\n",
    "        velerror = [params[7], params[10]]\n",
    "        # newhead['naxis'] = 3\n",
    "        # newhead['wcsaxes'] = 3\n",
    "        # newhead['naxis3'] = 2\n",
    "    elif parheader[\"NAXIS3\"] == 18:\n",
    "        velfield = [params[1], params[4], params[7]]\n",
    "        velerror = [params[10], params[13], params[16]]\n",
    "        # newhead['naxis'] = 3\n",
    "        # newhead['wcsaxes'] = 3\n",
    "        # newhead['naxis3'] = 3\n",
    "    return velfield, velerror, newhead\n",
    "\n",
    "def separate_vel_file(paramsfile):\n",
    "    params, parheader = fits.getdata(paramsfile, header=True)\n",
    "    velfield, velerror, newhead = separate_vel_comp(params, parheader)\n",
    "    if len(np.shape(velfield)) > 2:\n",
    "        for i in range(np.shape(velfield)[0]):\n",
    "            fits.writeto(paramsfile[:-5]+'_{}_vel.fits'.format(i+1), velfield[i], newhead, overwrite=True)\n",
    "            fits.writeto(paramsfile[:-5]+'_{}_vel_unc.fits'.format(i+1), velerror[i], newhead, overwrite=True)\n",
    "        \n",
    "    else:    \n",
    "        fits.writeto(paramsfile[:-5]+'_vel.fits', velfield, newhead, overwrite=True)\n",
    "        fits.writeto(paramsfile[:-5]+'_vel_unc.fits', velerror, newhead, overwrite=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c674626a-96f8-4c28-8843-0ee034052cde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x1_filtered_QA_vel.fits already exists and will not be overwritten\n",
      "File ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x2_filtered_QA_vel.fits already exists and will not be overwritten\n",
      "File ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_vel.fits already exists and will not be overwritten\n",
      "File ../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x1_filtered_QA_vel.fits already exists and will not be overwritten\n",
      "File ../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x2_filtered_QA_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/clusters_blue_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/clusters_red_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster_blue_HDBSCAN_N2Hp_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster_red_HDBSCAN_N2Hp_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster0_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster1_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster2_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster3_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster4_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster5_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n",
      "File ../clustering/cluster6_HDBSCAN_HC3N_vel.fits already exists and will not be overwritten\n"
     ]
    }
   ],
   "source": [
    "# we separate the velocity to save it apart in the cases needed\n",
    "\n",
    "filelist = np.concatenate([gaussifitfiles, fiberfiles, hc3nclusterfiles])\n",
    "\n",
    "for file in filelist:\n",
    "    if not os.path.exists(file[:-5]+'_vel.fits') or not os.path.exists(file[:-5]+'_vel_unc.fits') or overwrite:\n",
    "        print('Runing file {}'.format(file))\n",
    "        separate_vel_file(file)\n",
    "    else:\n",
    "        print('File {} already exists and will not be overwritten'.format(file[:-5]+'_vel.fits'))\n",
    "              \n",
    "\n",
    "# del newhead[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfe58e-e27f-4365-85f6-46c1dcb9cec5",
   "metadata": {},
   "source": [
    "Now that we separated the velocity from the files, we calculate the gradient in each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11aad031-6f0d-4350-824a-3059e5275ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_calc_save(velfile, velerrorfile, savefile, nbeams=2, distance=298*u.pc):\n",
    "    velheader = fits.getheader(velfile)\n",
    "\n",
    "    beammaj, beammin, pixwidth = (velheader['BMAJ'], velheader['BMIN'], velheader['CDELT2']) * u.deg\n",
    "    equivbeam = np.sqrt(beammaj * beammin) # equivalent circular beam\n",
    "    samplingwidth = equivbeam * nbeams  # 2 beams, we use this as a radius\n",
    "    print('The radius of the calculation area is {}'.format(np.round(samplingwidth.to(u.arcsec), 2)))\n",
    "    # the minimum number of pixels available is given in nyquist sampling\n",
    "    result_all = vgrad.vfit_image(velfile, velerrorfile,\n",
    "                              distance=298*u.pc, width = samplingwidth.to(u.arcsec))\n",
    "    grad_mag = result_all['grad']\n",
    "    grad_mag_err = result_all['grad_err']\n",
    "    gradmaghead = result_all['header'].copy()\n",
    "    gradmaghead['BUNIT'] = 'km s-1 pc-1'\n",
    "    gradmaghead['NAXIS'] = 3\n",
    "    gradmaghead['NAXIS3'] = 2\n",
    "    fits.writeto(savefile+'_magnitude.fits', [grad_mag, grad_mag_err], gradmaghead, overwrite=True)\n",
    "    grad_PA = result_all['posang']\n",
    "    grad_PA_err = result_all['paerr']\n",
    "    PAhead = gradmaghead.copy()\n",
    "    PAhead['BUNIT'] = 'deg'\n",
    "    fits.writeto(savefile+'_PA.fits', [grad_PA, grad_PA_err], gradmaghead, overwrite=True)\n",
    "    grad_vc = result_all['vc'].value\n",
    "    vchead = result_all['header'].copy()\n",
    "    fits.writeto(savefile+'_vc.fits', grad_vc, vchead, overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd1b4c8-ac39-43bd-873d-c07dfa94fb5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient calculation for file ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x1_filtered_QA.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x2_filtered_QA.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x1_filtered_QA.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x2_filtered_QA.fits already exists and will not be overwritten\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x2_filtered_QA_1.fits\n",
      "The radius of the calculation area is 9.58 arcsec\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x2_filtered_QA_2.fits\n",
      "The radius of the calculation area is 9.58 arcsec\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_1.fits\n",
      "The radius of the calculation area is 9.58 arcsec\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_2.fits\n",
      "The radius of the calculation area is 9.58 arcsec\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_3.fits\n",
      "The radius of the calculation area is 9.58 arcsec\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x2_filtered_QA_1.fits\n",
      "The radius of the calculation area is 11.24 arcsec\n",
      "Running gradient calculation for ../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x2_filtered_QA_2.fits\n",
      "The radius of the calculation area is 11.24 arcsec\n",
      "Gradient calculation for file ../clustering/clusters_blue_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/clusters_red_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster_blue_HDBSCAN_N2Hp.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster_red_HDBSCAN_N2Hp.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster0_HDBSCAN_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster1_HDBSCAN_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster2_HDBSCAN_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster3_HDBSCAN_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster4_HDBSCAN_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster5_HDBSCAN_HC3N.fits already exists and will not be overwritten\n",
      "Gradient calculation for file ../clustering/cluster6_HDBSCAN_HC3N.fits already exists and will not be overwritten\n"
     ]
    }
   ],
   "source": [
    "mle_extra_grad_files = [gaussfitfolder + s for s in ['HC3N/NGC1333-SE-mle-x2_filtered_QA_1.fits', 'HC3N/NGC1333-SE-mle-x2_filtered_QA_2.fits',\n",
    "                        'HC3N/NGC1333-SE-mle-x3_filtered_QA_1.fits', 'HC3N/NGC1333-SE-mle-x3_filtered_QA_2.fits',\n",
    "                        'HC3N/NGC1333-SE-mle-x3_filtered_QA_3.fits', 'N2Hp/NGC1333-SE-mle-x2_filtered_QA_1.fits',\n",
    "                        'N2Hp/NGC1333-SE-mle-x2_filtered_QA_2.fits']]\n",
    "\n",
    "filelist_new = np.concatenate([gaussifitfiles, mle_extra_grad_files, fiberfiles, hc3nclusterfiles])\n",
    "\n",
    "for file in filelist_new:\n",
    "    savefile = file[:-5]+'_vel_grad'\n",
    "    if not os.path.exists(savefile+'_magnitude.fits') or overwrite:\n",
    "        print('Running gradient calculation for {}'.format(file))\n",
    "        velfile = file[:-5]+'_vel.fits'\n",
    "        velfile_unc = file[:-5]+'_vel_unc.fits'\n",
    "        gradient_calc_save(velfile, velfile_unc, savefile) #if we run the function it will save\n",
    "    else:\n",
    "        print('Gradient calculation for file {} already exists and will not be overwritten'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8e4ad8-c1dc-4c52-8be2-858f09f743c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HC3N/NGC1333-SE-mle-x2_filtered_QA_1.fits../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x2_filtered_QA_2.fits../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_1.fits../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_2.fits../bayes_frame/nested-sampling/HC3N/NGC1333-SE-mle-x3_filtered_QA_3.fits../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x2_filtered_QA_1.fits../bayes_frame/nested-sampling/N2Hp/NGC1333-SE-mle-x2_filtered_QA_2.fits'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mle_extra_grad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16667ae0-ec2a-4bcc-90ca-6be1458a3a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
