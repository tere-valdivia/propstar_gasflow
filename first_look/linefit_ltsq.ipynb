{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb801be-ad56-48a7-973e-ed5b835d2248",
   "metadata": {},
   "source": [
    "# Line fitting using least squares\n",
    "\n",
    "This is to do a first decomposition of the spectra present in the HC$_3$N (10-9) data cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b51cfce-502d-46a6-9952-1570889303b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import *\n",
    "from astropy.wcs import WCS\n",
    "from astropy.io import fits\n",
    "import pyspeckit\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes, closing, disk, opening\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "# import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c54f9-a33c-4162-a27a-578b4526d094",
   "metadata": {},
   "source": [
    "## Preparation: loading files and making mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e41190-b1a5-49c5-9229-916efa44961c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e78a3f-c208-4a4b-a144-4eab3f0560b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames\n",
    "\n",
    "fitdir = 'gaussfit/'\n",
    "imagefile = hc3n_10_9_cube_s + '_K.fits'\n",
    "rmsfile = hc3n_10_9_cube_s + '_rms.fits'\n",
    "snrfile = hc3n_10_9_cube_s + '_K_-3.0_18.0_snr.fits'\n",
    "maskfile = fitdir + 'HC3N_10_9_mask'\n",
    "\n",
    "fitfile =  fitdir + 'HC3N_10_9_1G_fitparams.fits'\n",
    "fitfilefiltered = fitdir + 'HC3N_10_9_1G_fitparams_filtered.fits'\n",
    "newguessfile = fitdir + 'HC3N_10_9_1G_fitparams_filtered_guesses.fits'\n",
    "fitfile2 = fitdir + 'HC3N_10_9_1G_fitparams_2.fits'\n",
    "fitfile2filtered = fitdir + 'HC3N_10_9_1G_fitparams_2_filtered.fits'\n",
    "\n",
    "snratio = 4\n",
    "verbosity = False\n",
    "minsize = 1 #in beam area\n",
    "multicore = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f819-1abd-4e7a-87d7-cf51cf5d572a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "070fea12-0e92-412e-99cb-28ebbf4fa9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtersolutions(parcube, errcube, npeaks, rmsmap=None, snratio=None, \n",
    "                    velinit=-np.inf, velend=np.inf, filter_negative=False, \n",
    "                    errorfrac=None, eps=1.e-6, filter_islands=False, \n",
    "                    minsizetrim=50, chansize=0.08, masked_chans=False, \n",
    "                    velinit_mask=None, velend_mask=None, widthfilter=False):\n",
    "    \"\"\"\n",
    "    Replace the pixels in the fitted cube with np.nan where the fit is not\n",
    "    good enough according to our criteria.\n",
    "\n",
    "    The criteria that a pixel must have are:\n",
    "    - The errors are not zero (less than eps)\n",
    "    - The peak must not be negative in case filter_negatives is true\n",
    "    - The error fraction is lower than errorfrac, if given\n",
    "    - The central velocity value must be within the range [velinit,velend]\n",
    "    - The peak value must be larger than rms times snratio, if given\n",
    "    - If one parameter in a spectra is np.nan, all the spectra must be nan (sanity\n",
    "    check)\n",
    "    - NEW 10.5.22: the uncertainty in the central velocity must be smaller than the channel width\n",
    "    - NEW 11.5.22: if we masked certain channels, the central velocity of the components must not be within those channels\n",
    "\n",
    "    Args:\n",
    "        variable (type): description\n",
    "\n",
    "    Returns:\n",
    "        type: description\n",
    "\n",
    "    Raises:\n",
    "        Exception: description\n",
    "\n",
    "    \"\"\"\n",
    "    # we first create all the masks we need\n",
    "    \n",
    "    # all errors must be non zero\n",
    "    # note that eps must be larger than the velocity dispersion\n",
    "    zeromask = np.zeros(np.shape(parcube[0]), dtype=int) # we need to do a plane mask\n",
    "    for i in range(3*npeaks):\n",
    "        zeromask += np.where(np.abs(errcube[i])<eps, 1, 0)\n",
    "        \n",
    "    # if a fraction is given, make sure all values have an error fraction less than that\n",
    "    errormask = np.zeros(np.shape(parcube[0]), dtype=int)\n",
    "    if errorfrac is not None:\n",
    "        for i in range(3*npeaks):\n",
    "            errormask += np.where(np.abs(errcube[i]/parcube[i]) > errorfrac, 1, 0)\n",
    "            \n",
    "    # if indicated, the velocity width must not be larger than the selection range\n",
    "    widthmask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    if widthfilter:\n",
    "        for i in range(npeaks):\n",
    "            widthmask += np.where(parcube[2+3*i] > (velend-velinit)/2.35, 1, 0)\n",
    "        \n",
    "    \n",
    "    # if indicated, all values must be non-negative\n",
    "    negativemask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    if filter_negative:\n",
    "        for i in range(3*npeaks):\n",
    "            negativemask += np.where(parcube[i] < 0, 1, 0)\n",
    "    \n",
    "    # velocities must be within range\n",
    "    velocitymask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    for i in range(npeaks):\n",
    "        velocitymask += np.where(parcube[1+3*i] < velinit, 1, 0) + \\\n",
    "        np.where(parcube[1+3*i] > velend, 1, 0)\n",
    "    \n",
    "    # the amplitude of the Gaussian must be above the snratio indicated\n",
    "    peakmask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    if snratio is not None and rmsmap is not None:\n",
    "        for i in range(npeaks):\n",
    "            snrmappeak = parcube[3*i] / rmsmap\n",
    "            peakmask += np.where(snrmappeak < snratio, 1, 0)\n",
    "    \n",
    "    # all values of parameters and uncertainties must be not NaN\n",
    "    nanmask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    for i in range(3*npeaks):\n",
    "        nanmask += np.where(np.isnan(parcube[i]), 1, 0) + np.where(np.isnan(errcube[i]), 1, 0)\n",
    "    \n",
    "    # central velocity uncertainty must be lower than\n",
    "    centraluncertaintymask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    for i in range(npeaks):\n",
    "        velocitymask += np.where(errcube[1+3*i] > chansize, 1, 0)\n",
    "        \n",
    "    # if indicated, the central velocities must not be within masked channels\n",
    "    maskedchansmask = np.zeros(np.shape(zeromask), dtype=int)\n",
    "    if masked_chans:\n",
    "        for i in range(npeaks):\n",
    "            maskedchansmask += np.where(parcube[1+3*i] > velinit_mask, 1, 0) * np.where(parcube[1+3*i] < velend_mask, 1, 0)\n",
    "    \n",
    "    finalmask = zeromask + errormask + negativemask + widthmask + velocitymask + peakmask + nanmask + centraluncertaintymask + maskedchansmask\n",
    "    \n",
    "    parcubenew = parcube.copy()\n",
    "    errcubenew = errcube.copy()\n",
    "    parcubenew[np.where(np.repeat([finalmask], 3*npeaks, axis=0))] = np.nan\n",
    "    errcubenew[np.where(np.repeat([finalmask], 3*npeaks, axis=0))] = np.nan   \n",
    "    \n",
    "    # eliminate isolated small islands of emission after the filter\n",
    "    if filter_islands:        \n",
    "        planemask = ~np.isnan(parcubenew[0])\n",
    "        planemask = remove_small_objects(planemask, min_size=minsizetrim)\n",
    "        smallmask = np.ones(np.shape(planemask), dtype=int) - planemask\n",
    "        parcubenew[np.where(np.repeat([smallmask], 3*npeaks, axis=0))] = np.nan\n",
    "        errcubenew[np.where(np.repeat([smallmask], 3*npeaks, axis=0))] = np.nan\n",
    "    \n",
    "    return parcubenew, errcubenew\n",
    "\n",
    "\n",
    "# as each plane represents a different physical characteristic, and they do not necessarilly \n",
    "# correlate between each other, each plane of initguesses must be fit separately\n",
    "def interpolatesolutions(solfilein, npeaks, mask=None):\n",
    "    '''\n",
    "    The solfilein must be a .fits file that contains one parameter per \n",
    "    plane and then one parameter uncertainty per plane.\n",
    "    The shape must be [nplane, yy, xx]\n",
    "    The mask must be 2 dimensional\n",
    "    '''\n",
    "    solcube = fits.getdata(solfilein)[:3*npeaks]\n",
    "    if np.any(np.isnan(solcube)):\n",
    "        solcube[np.where(np.isnan(solcube))] = 0\n",
    "    solcubeshape = np.shape(solcube)\n",
    "    yy, xx = np.indices(solcubeshape[1:])\n",
    "    filledcube = solcube.copy()\n",
    "    headersolcube = fits.getheader(solfilein)\n",
    "\n",
    "    for i, plane in enumerate(solcube):\n",
    "        indexknown = np.where(plane<1e-5, False, True)\n",
    "        filledcube[i][~indexknown] = griddata((xx[indexknown], yy[indexknown]),\n",
    "                                                  plane[indexknown],\n",
    "                                                  (xx[~indexknown], yy[~indexknown])\n",
    "                                                 )\n",
    "        if mask is not None:\n",
    "            filledcube[i][np.where(mask==0)] = np.nan\n",
    "    return filledcube, headersolcube\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0bbc16-cd48-479f-bb6c-495b271921d3",
   "metadata": {},
   "source": [
    "### Create the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cde07bf-ff7d-4bba-bd3d-9591ae4a8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = pyspeckit.Cube(imagefile)\n",
    "header = cube.header\n",
    "\n",
    "beamarea, beamarea_pix2 = beam_size(header)\n",
    "minsizetrim = minsize * beamarea_pix2\n",
    "chansize = np.abs(header['CDELT3'])\n",
    "\n",
    "rmsmap = fits.getdata(rmsfile)\n",
    "snrmap, headerimage = fits.getdata(snrfile, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e767d76b-44aa-47f6-91f3-fe7233811381",
   "metadata": {},
   "outputs": [],
   "source": [
    "limitedmin=[True, True, True]\n",
    "limitedmax=[False, True, True]\n",
    "minpars=[0, velrange[0], 0]\n",
    "maxpars=[0, velrange[1], velrange[1]-velrange[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805c0e2e-1bbb-41d9-9543-d41a77fa706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Mask file\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(maskfile+'.fits'):\n",
    "    hdcube = headerimage.copy()\n",
    "    hdcube['BUNIT'] = ''\n",
    "    planemask = (snrmap > snratio)\n",
    "    fits.writeto(maskfile+'_0.fits', planemask.astype(int), hdcube)\n",
    "    # check the resulting mask map to see how much does the minimum size have to be and its connectivity\n",
    "    # before applying this filter\n",
    "    planemask = remove_small_objects(planemask, min_size=minsizetrim) # removes small islands of emission\n",
    "    fits.writeto(maskfile+'_1.fits', planemask.astype(int), hdcube)\n",
    "    planemask = remove_small_holes(planemask, area_threshold=minsizetrim) # fills small holes inside the emission area\n",
    "    fits.writeto(maskfile+'_2.fits', planemask.astype(int), hdcube)\n",
    "    planemask = closing(planemask, disk(1))\n",
    "    planemask = remove_small_holes(planemask, area_threshold=6)\n",
    "    fits.writeto(maskfile+'.fits', planemask.astype(int), hdcube)\n",
    "    print('Created Mask file')\n",
    "else:\n",
    "    planemask = fits.getdata(maskfile+'.fits')\n",
    "    print('Loaded Mask file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84501f7e-5ca0-440c-82e8-ad6198b1310f",
   "metadata": {},
   "source": [
    "## One Gaussian fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f958ea8e-873e-4929-a2a3-1d105337c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initguesses = [2, 8, 0.5]\n",
    "starting_point = (194,264)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "901e020e-73bf-4377-8c92-5866addb07fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Left region selection unchanged.  xminpix, xmaxpix: 0,195 [pyspeckit.spectrum.interactive]\n",
      "INFO: Left region selection unchanged.  xminpix, xmaxpix: 0,195 [pyspeckit.spectrum.interactive]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NaN or infinite values encountered in parameter cube.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(fitfile):\n",
    "    cube.fiteach(fittype='gaussian',\n",
    "                 signal_cut=snratio,\n",
    "                 guesses=initguesses,\n",
    "                 errmap = rmsmap, \n",
    "                 maskmap = planemask,\n",
    "                 limitedmin=limitedmin,\n",
    "                 limitedmax=limitedmax,\n",
    "                 minpars=minpars,\n",
    "                 maxpars=maxpars,\n",
    "                 use_neighbor_as_guess=True, \n",
    "                 start_from_point=starting_point,\n",
    "                 verbose=verbosity,\n",
    "                 multicore=multicore)\n",
    "    cube.write_fit(fitfile)\n",
    "    fittedmodel = cube.get_modelcube()\n",
    "    \n",
    "else:\n",
    "    cube.load_model_fit(fitfile, 3, fittype='gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c4133-5303-413b-beca-57ae1a0d5650",
   "metadata": {},
   "source": [
    "### Quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abfa33a9-bbe1-4fe9-9b74-482cc43faa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating filtered version.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(fitfilefiltered):\n",
    "    print(\"Creating filtered version.\") \n",
    "    parcube, errcube = filtersolutions(cube.parcube, cube.errcube, 1, \n",
    "                                       rmsmap=rmsmap, snratio=snratio, \n",
    "                                       velinit=velrange[0], velend=velrange[1], \n",
    "                                       filter_negative=True, errorfrac=0.5, \n",
    "                                       filter_islands=True, chansize=chansize)\n",
    "    cube.parcube = parcube\n",
    "    cube.errcube = errcube\n",
    "    cube.write_fit(fitfilefiltered) #(fitfile2filtered)\n",
    "    fittedmodel = cube.get_modelcube()\n",
    "    \n",
    "else:\n",
    "    print(\"Loading filtered version.\")\n",
    "    cube.load_model_fit(fitfilefiltered, 3, fittype='gaussian')\n",
    "    fittedmodel = cube.get_modelcube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b0c25d5-c552-4b80-8172-1ab0b8590759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating previous solutions.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(newguessfile):\n",
    "    print(\"Interpolating previous solutions.\")\n",
    "    newinitguess, headerguess = interpolatesolutions(fitfilefiltered, 1, mask=planemask)\n",
    "    fits.writeto(newguessfile, newinitguess, headerguess)\n",
    "    \n",
    "else:\n",
    "    print(\"Interpolation exists. Loading.\")\n",
    "    newinitguess = fits.getdata(newguessfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e044b8-33d6-4d67-9b46-75ba9dc45a05",
   "metadata": {},
   "source": [
    "### Second fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31b0aa2d-5f07-41aa-b7dc-9de86ab01721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fit\n",
      "INFO: Fitting up to 50709 spectra [pyspeckit.cubes.SpectralCube]\n",
      "INFO: Left region selection unchanged.  xminpix, xmaxpix: 0,195 [pyspeckit.spectrum.interactive]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean of empty slice\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "WARNING: gnorm=0.   wa2=[0. 0. 0.] [pyspeckit.mpfit.mpfit]\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(fitfile2):\n",
    "    print(\"Starting fit\")\n",
    "    cube.fiteach(fittype='gaussian',\n",
    "                 guesses=newinitguess,\n",
    "                 errmap = rmsmap, \n",
    "                 maskmap = planemask,\n",
    "                 limitedmin=limitedmin,\n",
    "                 limitedmax=limitedmax,\n",
    "                 minpars=minpars,\n",
    "                 maxpars=maxpars,\n",
    "                 use_neighbor_as_guess=True, \n",
    "                 start_from_point=starting_point,\n",
    "                 verbose=verbosity,\n",
    "                 verbose_level=1,\n",
    "                 multicore=multicore)\n",
    "    cube.write_fit(fitfile2)\n",
    "    fittedmodel = cube.get_modelcube()\n",
    "    \n",
    "else:\n",
    "    print(\"Fit 2 exists. Loading\")\n",
    "    cube.load_model_fit(fitfile2, 3, fittype='gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd55352d-40ce-4ead-906b-41e8fd18989a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating filtered version.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(fitfile2filtered):\n",
    "    print(\"Creating filtered version.\") \n",
    "    parcube, errcube = filtersolutions(cube.parcube, cube.errcube, 1, \n",
    "                                       rmsmap=rmsmap, snratio=snratio, \n",
    "                                       velinit=velrange[0], velend=velrange[1], \n",
    "                                       filter_negative=True, errorfrac=0.5, \n",
    "                                       filter_islands=True, chansize=chansize, widthfilter=True)\n",
    "    cube.parcube = parcube\n",
    "    cube.errcube = errcube\n",
    "    cube.write_fit(fitfile2filtered) #(fitfile2filtered)\n",
    "    fittedmodel = cube.get_modelcube()\n",
    "    \n",
    "else:\n",
    "    print(\"Loading filtered version.\")\n",
    "    cube.load_model_fit(fitfile2filtered, 3, fittype='gaussian')\n",
    "    fittedmodel = cube.get_modelcube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45d293-5217-4e72-b8ff-d8b8c0000d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
